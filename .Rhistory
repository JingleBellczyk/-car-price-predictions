get_hist_ylim <- function(column_data) {
hist_info <- hist(column_data, plot = FALSE)
return(c(3, max(hist_info$counts) * 1.2))  # Adding some space above the highest bar
}
# Function to get ylim for bar plots
get_barplot_ylim <- function(column_data) {
bar_info <- table(column_data)
return(c(0, max(bar_info) * 1.2))  # Adding some space above the highest bar
}
# Plot histograms for numeric columns
for (i in 1:n_numeric) {
column_data <- data[[numeric_columns[i]]]
hist(column_data, main = numeric_columns[i], xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
}
# Plot bar plots for non-numeric columns
for (i in 1:n_non_numeric) {
column_data <- data[[non_numeric_columns[i]]]
barplot(table(column_data), main = non_numeric_columns[i], xlab = "", col = "lightblue", border = "black", ylim = get_barplot_ylim(column_data), las=2,ylab="Count")
}
data
column_data <- data[["Mileage"]]
hist(column_data, main = "Mileage", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
#------------------------------------------------
q <- quantile(data$Mileage, 0.99)
data <- data[-which(data$Mileage > q), ]  # Remove rows where Mileage is greater than 99th percentile
data <- data[order(data$Mileage), ]  # Reset index
rownames(data) <- NULL  # Reset row names
#------------------------------------------------
column_data <- data[["Mileage"]]
hist(column_data, main = "Mileage", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
# Select only numeric columns
numeric_data <- data[sapply(data, is.numeric)]
# Display detailed descriptive statistics for numeric columns only
describe(numeric_data)
column_data <- data[["Year"]]
hist(column_data, main = "Year", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
#----------------------------
# Calculate the 1st percentile for the 'Year' column
q <- quantile(data$Year, 0.01)
# Remove rows where 'Year' is less than the 1st percentile
data <- data[data$Year >= q, ]
data <- data[order(data$Year), ]  # Reset index
rownames(data) <- NULL  # Reset row names
#----------------------------
# Display summary statistics
column_data <- data[["Year"]]
hist(column_data, main = "Year", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
# Select only numeric columns
numeric_data <- data[sapply(data, is.numeric)]
# Display detailed descriptive statistics for numeric columns only
describe(numeric_data)
# Create a histogram for the 'Model' column
histogram <- data.frame(Model = data$Model)
histogram$Count <- rep(1, nrow(data))
# Group by 'Model' and count the occurrences
histogram <- aggregate(Count ~ Model, data = histogram, FUN = length)
q <- 50
# Find models with a count less than the threshold 'q'
models_to_drop <- histogram$Model[histogram$Count < q]
# Get the number of models to drop
length(models_to_drop)
# Remove the 'Model' column from the data frame
data <- data[, !names(data) %in% "Model"]
# Install and load the 'psych' package for more detailed summary statistics
install.packages("psych")
library(psych)
# Assuming you have a dataframe named 'data'
# Remove rows where 'EngineV' is greater than 8.2
data <- data[data$EngineV <= 8.2, ]
# Reset the row indices
rownames(data) <- NULL
# Select only numeric columns
numeric_data <- data[sapply(data, is.numeric)]
# Display detailed descriptive statistics for numeric columns only
describe(numeric_data)
# Calculate the difference
difference <- 4345 - 3798
print(difference) # 547
# Division and expressing the result as a percentage
percentage <- (difference / 4345) * 100
print(percentage) # 12.6
if (!requireNamespace("dplyr", quietly = TRUE)) {
install.packages("dplyr")
}
x <- select(data, -Price)
y <- log(data$Price)
# Load necessary libraries
library(ggplot2)
# Number of rows of plots
n <- 4
# Extract the columns from 'x'
columns <- colnames(x)
# Create a list to store the plots
plot_list <- list()
# Loop through the columns and create scatter plots
for (i in 1:length(columns)) {
if (i > length(columns)) break # Break if there are no more columns
column <- columns[i]
p <- ggplot(data, aes_string(x = paste0('`', column, '`'), y = 'log(Price)')) +
geom_point() + # Create scatter plot
xlab(NULL) + # Remove x-axis label
ggtitle(paste(column, "and Price")) # Set plot title
plot_list[[i]] <- p # Store the plot in the list
}
# Print each plot separately
for (i in 1:length(plot_list)) {
print(plot_list[[i]])
}
install.packages("psych")
# Selecting independent continuous variables
continues_independent <- data[c("Mileage", "EngineV", "Year")]
# Performing F-test to obtain p-values
p_values <- round(summary(lm(log(Price) ~ Mileage + EngineV + Year, data))$coefficients[, 4], 3)
# Outputting the selected independent continuous variables
print(continues_independent)
# Install and load the 'recipes' package if not already installed
if (!require(recipes)) {
install.packages("recipes")
}
library(recipes)
# Create a recipe
rec <- recipe(~., data = x) %>%
step_dummy(all_nominal(), one_hot = TRUE)
# Prepare the recipe
rec <- prep(rec)
# Apply the recipe to create dummy variables
x_with_dummies <- bake(rec, new_data = x)
# Display the first 3 rows of the resulting data frame
head(x_with_dummies, 3)
# Install and load the 'recipes' package if not already installed
if (!require(recipes)) {
install.packages("recipes")
}
library(recipes)
# Create a recipe
rec <- recipe(~., data = x_with_dummies) %>%
step_scale(all_predictors())
# Prepare the recipe
rec <- prep(rec)
# Apply the recipe to scale the data
scaled_inputs <- bake(rec, new_data = x_with_dummies)
# Display the first 3 rows of the resulting scaled data frame
head(scaled_inputs, 3)
# Install and load the 'caret' package if not already installed
if (!require(caret)) {
install.packages("caret")
}
library(caret)
# Set the seed for reproducibility
set.seed(42)
# Split the data into training and testing sets
split <- createDataPartition(y, p = 0.8, list = FALSE)
if (!requireNamespace("tidyverse", quietly = TRUE)) {
install.packages("tidyverse")
}
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
if (!requireNamespace("car", quietly = TRUE)) {
install.packages("car")
}
if (!require(psych)) {
install.packages("psych")
}
# Load necessary libraries
library(tidyverse)  # Includes ggplot2, dplyr, and readr
library(caret)      # For modeling and preprocessing data
library(car)        # Contains functions for VIF (Variance Inflation Factor)
library(psych)
# Plot settings
theme_set(theme_minimal())
# Load data from CSV file
data <- read_csv("car_dataset.csv", show_col_types = FALSE)
data
numeric_data <- data[, sapply(data, is.numeric)]
# statistics about numeric data
describe(numeric_data)
# Load necessary libraries
library(tidyverse)  # Includes ggplot2, dplyr, and readr
# Numeric columns (assuming they contain only numeric data)
numeric_columns <- c("Price", "Mileage", "Year")  # Replace ... with actual column names
# Non-numeric columns (assuming they contain at least one non-numeric value)
non_numeric_columns <- c("Brand", "Body", "EngineV", "Engine Type", "Registration","Model")  # Replace ... with actual column names
# Define the number of rows of plots for each type
n_numeric <- length(numeric_columns)
n_non_numeric <- length(non_numeric_columns)
# Get the column names of the data
all_columns <- colnames(data)
# Function to get ylim for histograms
get_hist_ylim <- function(column_data) {
hist_info <- hist(column_data, plot = FALSE)
return(c(3, max(hist_info$counts) * 1.2))  # Adding some space above the highest bar
}
# Function to get ylim for bar plots
get_barplot_ylim <- function(column_data) {
bar_info <- table(column_data)
return(c(0, max(bar_info) * 1.2))  # Adding some space above the highest bar
}
# Plot histograms for numeric columns
for (i in 1:n_numeric) {
column_data <- data[[numeric_columns[i]]]
hist(column_data, main = numeric_columns[i], xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
}
# Plot bar plots for non-numeric columns
for (i in 1:n_non_numeric) {
column_data <- data[[non_numeric_columns[i]]]
barplot(table(column_data), main = non_numeric_columns[i], xlab = "", col = "lightblue", border = "black", ylim = get_barplot_ylim(column_data), las=2,ylab="Count")
}
data
column_data <- data[["Mileage"]]
hist(column_data, main = "Mileage", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
#------------------------------------------------
q <- quantile(data$Mileage, 0.99)
data <- data[-which(data$Mileage > q), ]  # Remove rows where Mileage is greater than 99th percentile
data <- data[order(data$Mileage), ]  # Reset index
rownames(data) <- NULL  # Reset row names
#------------------------------------------------
column_data <- data[["Mileage"]]
hist(column_data, main = "Mileage", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
# Select only numeric columns
numeric_data <- data[sapply(data, is.numeric)]
# Display detailed descriptive statistics for numeric columns only
describe(numeric_data)
column_data <- data[["Year"]]
hist(column_data, main = "Year", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
#----------------------------
# Calculate the 1st percentile for the 'Year' column
q <- quantile(data$Year, 0.01)
# Remove rows where 'Year' is less than the 1st percentile
data <- data[data$Year >= q, ]
data <- data[order(data$Year), ]  # Reset index
rownames(data) <- NULL  # Reset row names
#----------------------------
# Display summary statistics
column_data <- data[["Year"]]
hist(column_data, main = "Year", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
# Select only numeric columns
numeric_data <- data[sapply(data, is.numeric)]
# Display detailed descriptive statistics for numeric columns only
describe(numeric_data)
# Create a histogram for the 'Model' column
histogram <- data.frame(Model = data$Model)
histogram$Count <- rep(1, nrow(data))
# Group by 'Model' and count the occurrences
histogram <- aggregate(Count ~ Model, data = histogram, FUN = length)
q <- 50
# Find models with a count less than the threshold 'q'
models_to_drop <- histogram$Model[histogram$Count < q]
# Get the number of models to drop
length(models_to_drop)
# Remove the 'Model' column from the data frame
data <- data[, !names(data) %in% "Model"]
# Install and load the 'psych' package for more detailed summary statistics
install.packages("psych")
library(psych)
# Assuming you have a dataframe named 'data'
# Remove rows where 'EngineV' is greater than 8.2
data <- data[data$EngineV <= 8.2, ]
# Reset the row indices
rownames(data) <- NULL
# Select only numeric columns
numeric_data <- data[sapply(data, is.numeric)]
# Display detailed descriptive statistics for numeric columns only
describe(numeric_data)
# Calculate the difference
difference <- 4345 - 3798
print(difference) # 547
# Division and expressing the result as a percentage
percentage <- (difference / 4345) * 100
print(percentage) # 12.6
if (!requireNamespace("dplyr", quietly = TRUE)) {
install.packages("dplyr")
}
x <- select(data, -Price)
y <- log(data$Price)
# Load necessary libraries
library(ggplot2)
# Number of rows of plots
n <- 4
# Extract the columns from 'x'
columns <- colnames(x)
# Create a list to store the plots
plot_list <- list()
# Loop through the columns and create scatter plots
for (i in 1:length(columns)) {
if (i > length(columns)) break # Break if there are no more columns
column <- columns[i]
p <- ggplot(data, aes_string(x = paste0('`', column, '`'), y = 'log(Price)')) +
geom_point() + # Create scatter plot
xlab(NULL) + # Remove x-axis label
ggtitle(paste(column, "and Price")) # Set plot title
plot_list[[i]] <- p # Store the plot in the list
}
# Print each plot separately
for (i in 1:length(plot_list)) {
print(plot_list[[i]])
}
# Selecting independent continuous variables
continues_independent <- data[c("Mileage", "EngineV", "Year")]
# Performing F-test to obtain p-values
p_values <- round(summary(lm(log(Price) ~ Mileage + EngineV + Year, data))$coefficients[, 4], 3)
# Outputting the selected independent continuous variables
print(continues_independent)
# Install and load the 'recipes' package if not already installed
if (!require(recipes)) {
install.packages("recipes")
}
library(recipes)
# Create a recipe
rec <- recipe(~., data = x) %>%
step_dummy(all_nominal(), one_hot = TRUE)
# Prepare the recipe
rec <- prep(rec)
# Apply the recipe to create dummy variables
x_with_dummies <- bake(rec, new_data = x)
# Display the first 3 rows of the resulting data frame
head(x_with_dummies, 3)
# Install and load the 'recipes' package if not already installed
if (!require(recipes)) {
install.packages("recipes")
}
library(recipes)
# Create a recipe
rec <- recipe(~., data = x_with_dummies) %>%
step_scale(all_predictors())
# Prepare the recipe
rec <- prep(rec)
# Apply the recipe to scale the data
scaled_inputs <- bake(rec, new_data = x_with_dummies)
# Display the first 3 rows of the resulting scaled data frame
head(scaled_inputs, 3)
# Install and load the 'caret' package if not already installed
if (!require(caret)) {
install.packages("caret")
}
library(caret)
# Set the seed for reproducibility
set.seed(42)
# Split the data into training and testing sets
split <- createDataPartition(y, p = 0.8, list = FALSE)
install.packages("psych")
# Create a histogram for the 'Model' column
histogram <- data.frame(Model = data$Model)
histogram$Count <- rep(1, nrow(data))
if (!requireNamespace("tidyverse", quietly = TRUE)) {
install.packages("tidyverse")
}
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
if (!requireNamespace("car", quietly = TRUE)) {
install.packages("car")
}
if (!require(psych)) {
install.packages("psych")
}
# Load necessary libraries
library(tidyverse)  # Includes ggplot2, dplyr, and readr
library(caret)      # For modeling and preprocessing data
library(car)        # Contains functions for VIF (Variance Inflation Factor)
library(psych)
# Plot settings
theme_set(theme_minimal())
# Load data from CSV file
data <- read_csv("car_dataset.csv", show_col_types = FALSE)
data
numeric_data <- data[, sapply(data, is.numeric)]
# statistics about numeric data
describe(numeric_data)
describe(data)
# Install and load the 'psych' package for more detailed summary statistics
install.packages("psych")
library(psych)
# Assuming you have a dataframe named 'data'
# Remove rows where 'EngineV' is greater than 8.2
data <- data[data$EngineV <= 8.2, ]
# Reset the row indices
rownames(data) <- NULL
# Select only numeric columns
numeric_data <- data[sapply(data, is.numeric)]
# Display detailed descriptive statistics for numeric columns only
describe(numeric_data)
data
install.packages("psych")
if (!requireNamespace("tidyverse", quietly = TRUE)) {
install.packages("tidyverse")
}
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
if (!requireNamespace("car", quietly = TRUE)) {
install.packages("car")
}
if (!require(psych)) {
install.packages("psych")
}
# Load necessary libraries
library(tidyverse)  # Includes ggplot2, dplyr, and readr
library(caret)      # For modeling and preprocessing data
library(car)        # Contains functions for VIF (Variance Inflation Factor)
library(psych)
# Plot settings
theme_set(theme_minimal())
# Load data from CSV file
data <- read_csv("car_dataset.csv", show_col_types = FALSE)
data
numeric_data <- data[, sapply(data, is.numeric)]
# statistics about numeric data
describe(numeric_data)
# Load necessary libraries
library(tidyverse)  # Includes ggplot2, dplyr, and readr
# Numeric columns (assuming they contain only numeric data)
numeric_columns <- c("Price", "Mileage", "Year")  # Replace ... with actual column names
# Non-numeric columns (assuming they contain at least one non-numeric value)
non_numeric_columns <- c("Brand", "Body", "EngineV", "Engine Type", "Registration","Model")  # Replace ... with actual column names
# Define the number of rows of plots for each type
n_numeric <- length(numeric_columns)
n_non_numeric <- length(non_numeric_columns)
# Get the column names of the data
all_columns <- colnames(data)
# Function to get ylim for histograms
get_hist_ylim <- function(column_data) {
hist_info <- hist(column_data, plot = FALSE)
return(c(3, max(hist_info$counts) * 1.2))  # Adding some space above the highest bar
}
# Function to get ylim for bar plots
get_barplot_ylim <- function(column_data) {
bar_info <- table(column_data)
return(c(0, max(bar_info) * 1.2))  # Adding some space above the highest bar
}
# Plot histograms for numeric columns
for (i in 1:n_numeric) {
column_data <- data[[numeric_columns[i]]]
hist(column_data, main = numeric_columns[i], xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
}
# Plot bar plots for non-numeric columns
for (i in 1:n_non_numeric) {
column_data <- data[[non_numeric_columns[i]]]
barplot(table(column_data), main = non_numeric_columns[i], xlab = "", col = "lightblue", border = "black", ylim = get_barplot_ylim(column_data), las=2,ylab="Count")
}
data
column_data <- data[["Mileage"]]
hist(column_data, main = "Mileage", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
#------------------------------------------------
q <- quantile(data$Mileage, 0.99)
data <- data[-which(data$Mileage > q), ]  # Remove rows where Mileage is greater than 99th percentile
data <- data[order(data$Mileage), ]  # Reset index
rownames(data) <- NULL  # Reset row names
#------------------------------------------------
column_data <- data[["Mileage"]]
hist(column_data, main = "Mileage", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
# Select only numeric columns
numeric_data <- data[sapply(data, is.numeric)]
# Display detailed descriptive statistics for numeric columns only
describe(numeric_data)
column_data <- data[["Year"]]
hist(column_data, main = "Year", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
#----------------------------
# Calculate the 1st percentile for the 'Year' column
q <- quantile(data$Year, 0.01)
# Remove rows where 'Year' is less than the 1st percentile
data <- data[data$Year >= q, ]
data <- data[order(data$Year), ]  # Reset index
rownames(data) <- NULL  # Reset row names
#----------------------------
# Display summary statistics
column_data <- data[["Year"]]
hist(column_data, main = "Year", xlab = "", col = "lightblue", border = "black", ylim = get_hist_ylim(column_data),ylab="Count")
# Select only numeric columns
numeric_data <- data[sapply(data, is.numeric)]
# Display detailed descriptive statistics for numeric columns only
describe(numeric_data)
# Create a histogram for the 'Model' column
histogram <- data.frame(Model = data$Model)
histogram$Count <- rep(1, nrow(data))
# Group by 'Model' and count the occurrences
histogram <- aggregate(Count ~ Model, data = histogram, FUN = length)
q <- 50 #times of occuring
# Find models with a count less than the threshold 'q'
models_to_drop <- histogram$Model[histogram$Count < q]
# Get the number of models to drop
length(models_to_drop)
library(dplyr)
# Załóżmy, że masz ramkę danych 'df' z kolumną 'modele'
liczba_unikalnych_modeli <- df %>%
distinct(modele) %>%
nrow()
if (!requireNamespace("tidyverse", quietly = TRUE)) {
install.packages("tidyverse")
}
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
if (!requireNamespace("car", quietly = TRUE)) {
install.packages("car")
}
if (!require(psych)) {
install.packages("psych")
}
# Load necessary libraries
library(tidyverse)  # Includes ggplot2, dplyr, and readr
library(caret)      # For modeling and preprocessing data
library(car)        # Contains functions for VIF (Variance Inflation Factor)
library(psych)
# Plot settings
theme_set(theme_minimal())
# Load data from CSV file
data <- read_csv("car_dataset.csv", show_col_types = FALSE)
data
numeric_data <- data[, sapply(data, is.numeric)]
# statistics about numeric data
describe(numeric_data)
